{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš™ï¸ Vibration Fault Classification Training (CWRU)\n",
                "\n",
                "This notebook trains a **CNN** on the CWRU Bearing dataset.\n",
                "\n",
                "**Supports:**\n",
                "- 2D image data (spectrograms, 32x32)\n",
                "- 1D raw signal data (2048 samples)\n",
                "- Pre-processed .npz files\n",
                "- Raw .mat files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install scipy seaborn -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import numpy as np\n",
                "import scipy.io\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "import glob\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============= UPDATE THIS PATH =============\n",
                "DATA_PATH = '/content/drive/MyDrive/MaintanenceAI/Data/CWRU'\n",
                "SAVE_PATH = '/content/drive/MyDrive/MaintanenceAI/trained_models'\n",
                "# =============================================\n",
                "\n",
                "# Hyperparameters\n",
                "EPOCHS = 30\n",
                "BATCH_SIZE = 64\n",
                "LEARNING_RATE = 1e-3\n",
                "TEST_SPLIT = 0.2\n",
                "\n",
                "print(f'Data path: {DATA_PATH}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(data_path):\n",
                "    \"\"\"Load data from .npz file with auto-detection of format.\"\"\"\n",
                "    npz_files = glob.glob(os.path.join(data_path, '*.npz'))\n",
                "    if not npz_files:\n",
                "        raise FileNotFoundError(f'No .npz files found in {data_path}')\n",
                "    \n",
                "    npz_path = npz_files[0]\n",
                "    print(f'Loading: {npz_path}')\n",
                "    \n",
                "    data = np.load(npz_path, allow_pickle=True)\n",
                "    print(f'Available keys: {list(data.keys())}')\n",
                "    \n",
                "    # Try common key names\n",
                "    x_keys = ['X', 'x', 'data', 'signals', 'features', 'images']\n",
                "    y_keys = ['y', 'Y', 'labels', 'targets']\n",
                "    \n",
                "    X, y = None, None\n",
                "    keys = list(data.keys())\n",
                "    \n",
                "    for key in x_keys:\n",
                "        if key in data:\n",
                "            X = data[key]\n",
                "            break\n",
                "    if X is None:\n",
                "        X = data[keys[0]]\n",
                "    \n",
                "    for key in y_keys:\n",
                "        if key in data:\n",
                "            y = data[key]\n",
                "            break\n",
                "    if y is None and len(keys) > 1:\n",
                "        y = data[keys[1]]\n",
                "    \n",
                "    print(f'X shape: {X.shape}')\n",
                "    print(f'y shape: {y.shape}')\n",
                "    \n",
                "    return X, y\n",
                "\n",
                "# Load data\n",
                "print('Loading CWRU data...\\n')\n",
                "X, y = load_data(DATA_PATH)\n",
                "\n",
                "# Determine data type\n",
                "if len(X.shape) == 2:\n",
                "    DATA_TYPE = '1D'\n",
                "    print(f'\\nDetected: 1D signal data (shape: {X.shape})')\n",
                "elif len(X.shape) == 3:\n",
                "    DATA_TYPE = '2D'\n",
                "    print(f'\\nDetected: 2D image data (shape: {X.shape})')\n",
                "elif len(X.shape) == 4:\n",
                "    DATA_TYPE = '2D'\n",
                "    print(f'\\nDetected: 2D image data with channels (shape: {X.shape})')\n",
                "else:\n",
                "    raise ValueError(f'Unexpected data shape: {X.shape}')\n",
                "\n",
                "# Handle labels\n",
                "le = LabelEncoder()\n",
                "if y.dtype == object or (len(y.shape) == 1 and isinstance(y[0], str)):\n",
                "    y = le.fit_transform(y)\n",
                "else:\n",
                "    y = y.astype(int)\n",
                "    if len(y.shape) > 1:\n",
                "        y = y.flatten()\n",
                "    n_classes = len(np.unique(y))\n",
                "    label_names = [f'Class_{i}' for i in range(n_classes)]\n",
                "    le.classes_ = np.array(label_names)\n",
                "\n",
                "NUM_CLASSES = len(np.unique(y))\n",
                "print(f'Number of classes: {NUM_CLASSES}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Class distribution\n",
                "unique, counts = np.unique(y, return_counts=True)\n",
                "print('\\nClass Distribution:')\n",
                "for cls, cnt in zip(unique, counts):\n",
                "    name = le.classes_[cls] if cls < len(le.classes_) else f'Class_{cls}'\n",
                "    print(f'  {name}: {cnt} samples')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/test split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=TEST_SPLIT, random_state=42, stratify=y\n",
                ")\n",
                "print(f'Train: {len(X_train)}, Test: {len(X_test)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VibrationClassifier1D(nn.Module):\n",
                "    \"\"\"1D CNN for raw signal data.\"\"\"\n",
                "    def __init__(self, num_classes=10):\n",
                "        super().__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv1d(1, 16, kernel_size=64, stride=2, padding=32),\n",
                "            nn.BatchNorm1d(16), nn.ReLU(), nn.MaxPool1d(2),\n",
                "            nn.Conv1d(16, 32, kernel_size=32, stride=2, padding=16),\n",
                "            nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
                "            nn.Conv1d(32, 64, kernel_size=16, stride=2, padding=8),\n",
                "            nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
                "            nn.Conv1d(64, 128, kernel_size=8, stride=2, padding=4),\n",
                "            nn.BatchNorm1d(128), nn.ReLU(),\n",
                "            nn.AdaptiveAvgPool1d(1)\n",
                "        )\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(128, 64), nn.ReLU(),\n",
                "            nn.Linear(64, num_classes)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = x.view(x.size(0), -1)\n",
                "        return self.classifier(x)\n",
                "\n",
                "\n",
                "class VibrationClassifier2D(nn.Module):\n",
                "    \"\"\"2D CNN for spectrogram/image data.\"\"\"\n",
                "    def __init__(self, num_classes=10, input_channels=1):\n",
                "        super().__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(256), nn.ReLU(),\n",
                "            nn.AdaptiveAvgPool2d(1)\n",
                "        )\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(256, 128), nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(128, num_classes)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = x.view(x.size(0), -1)\n",
                "        return self.classifier(x)\n",
                "\n",
                "\n",
                "# Select model based on data type\n",
                "if DATA_TYPE == '1D':\n",
                "    model = VibrationClassifier1D(num_classes=NUM_CLASSES).to(device)\n",
                "    print('Using 1D CNN model')\n",
                "else:\n",
                "    # Determine input channels\n",
                "    if len(X.shape) == 3:\n",
                "        input_channels = 1\n",
                "    else:\n",
                "        input_channels = X.shape[1] if X.shape[1] in [1, 3] else 1\n",
                "    model = VibrationClassifier2D(num_classes=NUM_CLASSES, input_channels=input_channels).to(device)\n",
                "    print(f'Using 2D CNN model (input channels: {input_channels})')\n",
                "\n",
                "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Dataset & DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CWRUDataset(Dataset):\n",
                "    def __init__(self, data, labels, data_type='2D'):\n",
                "        self.data = data\n",
                "        self.labels = labels\n",
                "        self.data_type = data_type\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        x = self.data[idx].astype(np.float32)\n",
                "        \n",
                "        # Normalize\n",
                "        x = (x - np.mean(x)) / (np.std(x) + 1e-8)\n",
                "        \n",
                "        if self.data_type == '1D':\n",
                "            # Shape: (1, signal_length)\n",
                "            x = torch.tensor(x).unsqueeze(0)\n",
                "        else:\n",
                "            # Shape: (1, H, W) for 2D\n",
                "            if len(x.shape) == 2:\n",
                "                x = torch.tensor(x).unsqueeze(0)\n",
                "            elif len(x.shape) == 3:\n",
                "                # Already has channels, just convert\n",
                "                x = torch.tensor(x)\n",
                "                # If channels are last, move to first\n",
                "                if x.shape[0] not in [1, 3] and x.shape[-1] in [1, 3]:\n",
                "                    x = x.permute(2, 0, 1)\n",
                "            else:\n",
                "                x = torch.tensor(x)\n",
                "        \n",
                "        return x, torch.tensor(self.labels[idx], dtype=torch.long)\n",
                "\n",
                "\n",
                "train_dataset = CWRUDataset(X_train, y_train, DATA_TYPE)\n",
                "test_dataset = CWRUDataset(X_test, y_test, DATA_TYPE)\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "\n",
                "# Verify shapes\n",
                "sample_x, sample_y = next(iter(train_loader))\n",
                "print(f'Batch shape: {sample_x.shape}')\n",
                "print(f'Labels shape: {sample_y.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
                "\n",
                "train_losses, train_accs = [], []\n",
                "\n",
                "print('Starting Training...\\n')\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    \n",
                "    for data, target in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}', leave=False):\n",
                "        data, target = data.to(device), target.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = criterion(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        pred = output.argmax(dim=1)\n",
                "        correct += pred.eq(target).sum().item()\n",
                "        total += target.size(0)\n",
                "    \n",
                "    avg_loss = total_loss / len(train_loader)\n",
                "    accuracy = 100. * correct / total\n",
                "    train_losses.append(avg_loss)\n",
                "    train_accs.append(accuracy)\n",
                "    scheduler.step(avg_loss)\n",
                "    \n",
                "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
                "\n",
                "print('\\nâœ… Training Complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "all_preds, all_targets = [], []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        data, target = data.to(device), target.to(device)\n",
                "        output = model(data)\n",
                "        pred = output.argmax(dim=1)\n",
                "        all_preds.extend(pred.cpu().numpy())\n",
                "        all_targets.extend(target.cpu().numpy())\n",
                "\n",
                "all_preds = np.array(all_preds)\n",
                "all_targets = np.array(all_targets)\n",
                "\n",
                "test_accuracy = 100. * np.mean(all_preds == all_targets)\n",
                "print(f'\\nðŸ“Š Test Accuracy: {test_accuracy:.2f}%')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classification Report\n",
                "print('\\nClassification Report:')\n",
                "print(classification_report(all_targets, all_preds, target_names=le.classes_))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "cm = confusion_matrix(all_targets, all_preds)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
                "plt.title(f'Confusion Matrix (Accuracy: {test_accuracy:.1f}%)')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(SAVE_PATH, exist_ok=True)\n",
                "save_file = os.path.join(SAVE_PATH, 'vibration_classifier.pth')\n",
                "\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'label_encoder_classes': le.classes_.tolist(),\n",
                "    'test_accuracy': test_accuracy,\n",
                "    'num_classes': NUM_CLASSES,\n",
                "    'data_type': DATA_TYPE,\n",
                "    'model_type': '2D' if DATA_TYPE == '2D' else '1D'\n",
                "}, save_file)\n",
                "\n",
                "print(f'âœ… Model saved: {save_file}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training curves\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "axes[0].plot(train_losses)\n",
                "axes[0].set_title('Training Loss')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].grid(True)\n",
                "\n",
                "axes[1].plot(train_accs)\n",
                "axes[1].set_title('Training Accuracy')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Accuracy (%)')\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=150)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}