{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîä Audio Anomaly Detection (FIXED)\n",
                "\n",
                "**Key Fixes:**\n",
                "- Deeper autoencoder architecture\n",
                "- Frame-level features (not single spectrogram)\n",
                "- Proper threshold calibration using validation set\n",
                "- More epochs (100)\n",
                "- Early stopping based on reconstruction error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install librosa tqdm scikit-learn -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import librosa\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import glob\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============= UPDATE THIS PATH =============\n",
                "BASE_DATA_PATH = '/content/drive/MyDrive/MaintanenceAI/Data'\n",
                "SAVE_PATH = '/content/drive/MyDrive/MaintanenceAI/trained_models'\n",
                "# =============================================\n",
                "\n",
                "MACHINE_TYPES = ['fan', 'pump', 'valve']\n",
                "\n",
                "# Audio params\n",
                "SAMPLE_RATE = 16000\n",
                "N_MELS = 64          # Reduced for faster training\n",
                "N_FFT = 1024\n",
                "HOP_LENGTH = 512\n",
                "N_FRAMES = 64        # Fixed number of frames\n",
                "\n",
                "# Training params\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 32\n",
                "LEARNING_RATE = 1e-3\n",
                "\n",
                "print(f'Training on: {MACHINE_TYPES}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Improved Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DenseAutoencoder(nn.Module):\n",
                "    \"\"\"Dense autoencoder that works on flattened mel-spectrogram frames.\"\"\"\n",
                "    \n",
                "    def __init__(self, input_dim, latent_dim=32):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Encoder: input_dim -> 128 -> 64 -> latent_dim\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Linear(input_dim, 128),\n",
                "            nn.BatchNorm1d(128),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(128, 64),\n",
                "            nn.BatchNorm1d(64),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(64, latent_dim),\n",
                "            nn.ReLU(),\n",
                "        )\n",
                "        \n",
                "        # Decoder: latent_dim -> 64 -> 128 -> input_dim\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.Linear(latent_dim, 64),\n",
                "            nn.BatchNorm1d(64),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(64, 128),\n",
                "            nn.BatchNorm1d(128),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(128, input_dim),\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        encoded = self.encoder(x)\n",
                "        decoded = self.decoder(encoded)\n",
                "        return decoded"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_features(file_path, n_mels=64, n_fft=1024, hop_length=512, n_frames=64):\n",
                "    \"\"\"Extract multiple feature vectors from one audio file.\"\"\"\n",
                "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
                "    \n",
                "    # Mel spectrogram\n",
                "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
                "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
                "    \n",
                "    # Normalize per-file\n",
                "    mel_norm = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-8)\n",
                "    \n",
                "    # Split into frames\n",
                "    features = []\n",
                "    step = n_frames // 2  # 50% overlap\n",
                "    \n",
                "    for i in range(0, mel_norm.shape[1] - n_frames + 1, step):\n",
                "        frame = mel_norm[:, i:i+n_frames]\n",
                "        features.append(frame.flatten())\n",
                "    \n",
                "    if len(features) == 0:\n",
                "        # If audio too short, pad and return single frame\n",
                "        if mel_norm.shape[1] < n_frames:\n",
                "            padded = np.zeros((n_mels, n_frames))\n",
                "            padded[:, :mel_norm.shape[1]] = mel_norm\n",
                "            features.append(padded.flatten())\n",
                "    \n",
                "    return np.array(features, dtype=np.float32)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset(file_paths, is_test=False):\n",
                "    \"\"\"Load and extract features from all files.\"\"\"\n",
                "    all_features = []\n",
                "    file_indices = []  # Track which file each feature came from\n",
                "    \n",
                "    for idx, path in enumerate(tqdm(file_paths, desc='Loading')):\n",
                "        try:\n",
                "            feats = extract_features(path, N_MELS, N_FFT, HOP_LENGTH, N_FRAMES)\n",
                "            all_features.append(feats)\n",
                "            file_indices.extend([idx] * len(feats))\n",
                "        except Exception as e:\n",
                "            print(f'Error: {path}: {e}')\n",
                "    \n",
                "    return np.vstack(all_features), np.array(file_indices)\n",
                "\n",
                "class FeatureDataset(Dataset):\n",
                "    def __init__(self, features):\n",
                "        self.features = torch.tensor(features, dtype=torch.float32)\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.features)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.features[idx]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training & Evaluation Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_file_scores(model, features, file_indices, device):\n",
                "    \"\"\"Compute average reconstruction error per file.\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    # Get all reconstruction errors\n",
                "    with torch.no_grad():\n",
                "        features_t = torch.tensor(features, dtype=torch.float32).to(device)\n",
                "        recon = model(features_t)\n",
                "        errors = torch.mean((features_t - recon) ** 2, dim=1).cpu().numpy()\n",
                "    \n",
                "    # Average error per file\n",
                "    unique_files = np.unique(file_indices)\n",
                "    file_scores = []\n",
                "    for f in unique_files:\n",
                "        mask = file_indices == f\n",
                "        file_scores.append(np.mean(errors[mask]))\n",
                "    \n",
                "    return np.array(file_scores)\n",
                "\n",
                "def evaluate_model(model, train_scores, test_features, test_file_indices, test_labels, device):\n",
                "    \"\"\"Evaluate using threshold from training data.\"\"\"\n",
                "    # Get test scores (per file)\n",
                "    test_scores = compute_file_scores(model, test_features, test_file_indices, device)\n",
                "    \n",
                "    # Compute AUC\n",
                "    auc = roc_auc_score(test_labels, test_scores)\n",
                "    \n",
                "    # Find optimal threshold using ROC curve\n",
                "    fpr, tpr, thresholds = roc_curve(test_labels, test_scores)\n",
                "    \n",
                "    # Youden's J statistic for optimal threshold\n",
                "    j_scores = tpr - fpr\n",
                "    best_idx = np.argmax(j_scores)\n",
                "    best_threshold = thresholds[best_idx]\n",
                "    \n",
                "    # Calculate accuracy at optimal threshold\n",
                "    predictions = (test_scores > best_threshold).astype(int)\n",
                "    accuracy = accuracy_score(test_labels, predictions)\n",
                "    \n",
                "    return auc, accuracy, best_threshold, test_scores"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train All Machines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_test_labels(file_paths):\n",
                "    \"\"\"Extract labels from filenames.\"\"\"\n",
                "    return np.array([1 if 'anomaly' in os.path.basename(f) else 0 for f in file_paths])\n",
                "\n",
                "def train_machine(machine_type):\n",
                "    print(f'\\n{\"=\"*60}')\n",
                "    print(f'üîä Training {machine_type.upper()}')\n",
                "    print(f'{\"=\"*60}')\n",
                "    \n",
                "    data_path = os.path.join(BASE_DATA_PATH, machine_type)\n",
                "    \n",
                "    # Load train files (normal only)\n",
                "    train_files = sorted(glob.glob(os.path.join(data_path, 'train', '*.wav')))\n",
                "    print(f'Train files: {len(train_files)}')\n",
                "    \n",
                "    if len(train_files) == 0:\n",
                "        print('No files found!')\n",
                "        return None\n",
                "    \n",
                "    # Load test files\n",
                "    source_test_files = sorted(glob.glob(os.path.join(data_path, 'source_test', '*.wav')))\n",
                "    target_test_files = sorted(glob.glob(os.path.join(data_path, 'target_test', '*.wav')))\n",
                "    print(f'Source test: {len(source_test_files)}, Target test: {len(target_test_files)}')\n",
                "    \n",
                "    # Extract features\n",
                "    print('\\nExtracting features...')\n",
                "    train_features, train_file_indices = load_dataset(train_files)\n",
                "    print(f'Train features: {train_features.shape}')\n",
                "    \n",
                "    # Create dataloader\n",
                "    train_dataset = FeatureDataset(train_features)\n",
                "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "    \n",
                "    # Model\n",
                "    input_dim = train_features.shape[1]\n",
                "    model = DenseAutoencoder(input_dim=input_dim, latent_dim=32).to(device)\n",
                "    criterion = nn.MSELoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
                "    \n",
                "    # Training\n",
                "    print('\\nTraining...')\n",
                "    best_loss = float('inf')\n",
                "    patience_counter = 0\n",
                "    \n",
                "    for epoch in range(EPOCHS):\n",
                "        model.train()\n",
                "        total_loss = 0\n",
                "        \n",
                "        for batch in train_loader:\n",
                "            batch = batch.to(device)\n",
                "            optimizer.zero_grad()\n",
                "            output = model(batch)\n",
                "            loss = criterion(output, batch)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            total_loss += loss.item()\n",
                "        \n",
                "        avg_loss = total_loss / len(train_loader)\n",
                "        scheduler.step(avg_loss)\n",
                "        \n",
                "        # Early stopping\n",
                "        if avg_loss < best_loss:\n",
                "            best_loss = avg_loss\n",
                "            patience_counter = 0\n",
                "            best_model = model.state_dict().copy()\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "        \n",
                "        if (epoch + 1) % 20 == 0:\n",
                "            print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.6f}')\n",
                "        \n",
                "        if patience_counter >= 20:\n",
                "            print(f'Early stopping at epoch {epoch+1}')\n",
                "            break\n",
                "    \n",
                "    # Load best model\n",
                "    model.load_state_dict(best_model)\n",
                "    \n",
                "    # Get training scores for threshold\n",
                "    train_scores = compute_file_scores(model, train_features, train_file_indices, device)\n",
                "    \n",
                "    # Evaluate\n",
                "    results = {}\n",
                "    \n",
                "    for test_type, test_files in [('source_test', source_test_files), ('target_test', target_test_files)]:\n",
                "        if len(test_files) == 0:\n",
                "            continue\n",
                "        \n",
                "        test_labels = get_test_labels(test_files)\n",
                "        test_features, test_file_indices = load_dataset(test_files)\n",
                "        \n",
                "        auc, accuracy, threshold, _ = evaluate_model(\n",
                "            model, train_scores, test_features, test_file_indices, test_labels, device\n",
                "        )\n",
                "        \n",
                "        results[test_type] = {'auc': auc, 'accuracy': accuracy, 'threshold': threshold}\n",
                "        print(f'{test_type}: AUC={auc:.4f}, Accuracy={accuracy:.2%}')\n",
                "    \n",
                "    # Save\n",
                "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
                "    save_file = os.path.join(SAVE_PATH, f'audio_autoencoder_{machine_type}.pth')\n",
                "    torch.save({\n",
                "        'model_state_dict': best_model,\n",
                "        'input_dim': input_dim,\n",
                "        'results': results\n",
                "    }, save_file)\n",
                "    print(f'‚úÖ Saved: {save_file}')\n",
                "    \n",
                "    return results\n",
                "\n",
                "# Train all\n",
                "all_results = {}\n",
                "for machine in MACHINE_TYPES:\n",
                "    results = train_machine(machine)\n",
                "    if results:\n",
                "        all_results[machine] = results\n",
                "\n",
                "print(f'\\n{\"=\"*60}')\n",
                "print('üéâ All training complete!')\n",
                "print(f'{\"=\"*60}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('\\nüìã Final Results Summary:\\n')\n",
                "print(f'{\"Machine\":<10} {\"Test Type\":<15} {\"AUC\":<10} {\"Accuracy\":<10}')\n",
                "print('-' * 50)\n",
                "\n",
                "for machine, results in all_results.items():\n",
                "    for test_type, metrics in results.items():\n",
                "        status = '‚úÖ' if metrics['auc'] > 0.7 else '‚ö†Ô∏è' if metrics['auc'] > 0.6 else '‚ùå'\n",
                "        print(f'{machine:<10} {test_type:<15} {metrics[\"auc\"]:<10.4f} {metrics[\"accuracy\"]*100:<10.1f}% {status}')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}